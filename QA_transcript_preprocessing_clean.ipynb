{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CI4LKZ_UYIH"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDPrleX1ULum"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import ast\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R3Q4aPGU23v"
      },
      "source": [
        "# Extract separate questions and answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIxbMLIOGz7B"
      },
      "outputs": [],
      "source": [
        "# Specify personal OpenAI key\n",
        "client = OpenAI(\n",
        "  api_key=\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiRugiWsER-2"
      },
      "outputs": [],
      "source": [
        "# Function to extract questions from text possibly containing multiple questions\n",
        "def extract_questions_answers(questions, answers):\n",
        "  # Prompt to instruct the model\n",
        "  prompt = f\"\"\"\n",
        "  Extract each distinct question from the following question transcript.\n",
        "  Keep multi-sentence questions grouped together so that the supporting context remains intact.\n",
        "\n",
        "  Then extract the answers given to the extracted questions from the following answer transcript.\n",
        "  Keep multi-sentence answers grouped together so that the supporting context remains intact.\n",
        "  If a question is not answered, state 'NOT ANSWERED'.\n",
        "\n",
        "  For each [Question, Answer] pair, also assign a numerical score between 0 and 1 with 1 decimal for how directly the answer addresses the question where a score of 1 means the question was fully answered and a score of 0 means the question was fully avoided.\n",
        "\n",
        "  Return your response in **strict Python list format**:\n",
        "\n",
        "  [\n",
        "    ['question 1', 'answer 1', answer_score],\n",
        "    ['question 2', 'answer 2', answer_score],\n",
        "    ...\n",
        "  ]\n",
        "\n",
        "  Question transcript:\n",
        "  {questions}\n",
        "\n",
        "  Answer transcript:\n",
        "  {answers}\n",
        "  \"\"\"\n",
        "\n",
        "  # Call Open AI model\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"gpt-5-mini\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are an assistant that extracts and matches questions and answers from Q&A transcripts, and checks to which extent the question was answered or avoided.\"},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "  )\n",
        "  return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9n9uLqopN35"
      },
      "outputs": [],
      "source": [
        "# Function to check question orientation and theme\n",
        "def check_question_properties(question):\n",
        "  prompt = f\"\"\"\n",
        "  Classify the following question along two dimensions:\n",
        "\n",
        "  1. Orientation:\n",
        "      - 'Past' → asking about past or current performance\n",
        "      - 'Future' → asking about guidance, expectations, or outlook\n",
        "      - 'Mixed' → contains both past and future elements\n",
        "\n",
        "  2. Theme:\n",
        "      Choose one from the following:\n",
        "      - 'Profitability'\n",
        "      - 'Capital & Liquidity'\n",
        "      - 'Macro & Geopolitical influences'\n",
        "      - 'Regulatory & Legal'\n",
        "      - 'Risk management'\n",
        "      - 'Technology & Innovation'\n",
        "      - 'Sustainability'\n",
        "      - 'Strategy & Management'\n",
        "      - 'Other' (if none apply)\n",
        "\n",
        "  Return your response in **strict Python list format**:\n",
        "  ['orientation', 'theme']\n",
        "\n",
        "  Question:\n",
        "  {question}\n",
        "  \"\"\"\n",
        "\n",
        "  # Call Open AI model\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"gpt-5-nano\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are an assistant that classifies financial Q&A questions.\"},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "  )\n",
        "  return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHMFZNjBGSbf"
      },
      "outputs": [],
      "source": [
        "#import data\n",
        "all_qas = pd.read_csv(\"citi_Q&A_blocks_2013_2025_FINAL.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkjcZ01vHQ87",
        "outputId": "3b99faa8-2a8e-4847-d6c9-ec7bf4bb57bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      bank  year quarter  tag question_speaker  analyst_firm  \\\n",
            "1888  Citi  2023      Q1  NaN     Glenn Schorr           NaN   \n",
            "1889  Citi  2023      Q1  NaN     Glenn Schorr           NaN   \n",
            "1890  Citi  2023      Q1  NaN        Mike Mayo           NaN   \n",
            "1891  Citi  2023      Q1  NaN        Mike Mayo           NaN   \n",
            "1892  Citi  2023      Q1  NaN    Betsy Graseck           NaN   \n",
            "...    ...   ...     ...  ...              ...           ...   \n",
            "1969  Citi  2023      Q4   FY     Vivek Juneja           NaN   \n",
            "1970  Citi  2023      Q4   FY     Vivek Juneja           NaN   \n",
            "1971  Citi  2023      Q4   FY    Steven Chubak           NaN   \n",
            "1972  Citi  2023      Q4   FY    Steven Chubak           NaN   \n",
            "1973  Citi  2023      Q4   FY        Mike Mayo           NaN   \n",
            "\n",
            "                                               question  \\\n",
            "1888  Hi, thank you, a simple one. I appreciate the ...   \n",
            "1889  I appreciate that. Maybe if I could follow-up ...   \n",
            "1890  Hi, Jane, I challenged you a couple earnings c...   \n",
            "1891  Okay. And then as it relates to rates generall...   \n",
            "1892  Hi, good morning. I know during the prepared r...   \n",
            "...                                                 ...   \n",
            "1969  Hi Jane, hi Mark. Couple of quick clarificatio...   \n",
            "1970  Okay. And then, Jane, to your point about the ...   \n",
            "1971  Hi, thanks for taking my questions. Really jus...   \n",
            "1972  Got it. And just on the earlier comments you m...   \n",
            "1973  Yeah, just a clarification. When you said medi...   \n",
            "\n",
            "                answer_speaker  \\\n",
            "1888                Mark Mason   \n",
            "1889  Jane Fraser | Mark Mason   \n",
            "1890               Jane Fraser   \n",
            "1891                Mark Mason   \n",
            "1892  Jane Fraser | Mark Mason   \n",
            "...                        ...   \n",
            "1969                Mark Mason   \n",
            "1970               Jane Fraser   \n",
            "1971                Mark Mason   \n",
            "1972                Mark Mason   \n",
            "1973  Mark Mason | Jane Fraser   \n",
            "\n",
            "                                                 answer  \n",
            "1888  Yeah, thanks, Glenn, and good morning. Appreci...  \n",
            "1889  Glenn, I'll kick it off and pass it over to Ma...  \n",
            "1890  Oh, thank you, Mike, and a great question. I t...  \n",
            "1891  Yeah, so again, I think that there is certainl...  \n",
            "1892  Hey there Betsy. So, we're obviously delighted...  \n",
            "...                                                 ...  \n",
            "1969  Modest declines outside, but yes declines outs...  \n",
            "1970  So let me just be clear about where the ones t...  \n",
            "1971  So, let's see, so obviously, the proposal is o...  \n",
            "1972  I mean, there are a lot of factors in there. T...  \n",
            "1973              Yeah. 2026. By 2026. Thank you, Mike.  \n",
            "\n",
            "[86 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "# Filter for data in batches\n",
        "filtered_qas = all_qas[all_qas[\"year\"] <= 2023]\n",
        "filtered_qas = filtered_qas[filtered_qas[\"year\"] > 2022]\n",
        "\n",
        "qa_pairs = filtered_qas\n",
        "\n",
        "print(qa_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJN6vOtoMBE3",
        "outputId": "aba6b845-5b33-482b-9a14-22025d59975e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed block: 1 of 86, extracted 1 questions and answers.\n",
            "Processed block: 2 of 86, extracted 1 questions and answers.\n",
            "Processed block: 3 of 86, extracted 1 questions and answers.\n",
            "Processed block: 4 of 86, extracted 3 questions and answers.\n",
            "Processed block: 5 of 86, extracted 1 questions and answers.\n",
            "Processed block: 6 of 86, extracted 1 questions and answers.\n",
            "Processed block: 7 of 86, extracted 1 questions and answers.\n",
            "Processed block: 8 of 86, extracted 1 questions and answers.\n",
            "Processed block: 9 of 86, extracted 1 questions and answers.\n",
            "Processed block: 10 of 86, extracted 1 questions and answers.\n",
            "Processed block: 11 of 86, extracted 2 questions and answers.\n",
            "Processed block: 12 of 86, extracted 1 questions and answers.\n",
            "Processed block: 13 of 86, extracted 1 questions and answers.\n",
            "Processed block: 14 of 86, extracted 2 questions and answers.\n",
            "Processed block: 15 of 86, extracted 1 questions and answers.\n",
            "Processed block: 16 of 86, extracted 1 questions and answers.\n",
            "Processed block: 17 of 86, extracted 1 questions and answers.\n",
            "Processed block: 18 of 86, extracted 1 questions and answers.\n",
            "Processed block: 19 of 86, extracted 1 questions and answers.\n",
            "Processed block: 20 of 86, extracted 1 questions and answers.\n",
            "Skipping invalid item in LLM output: [\"And if you define deposits this way, I mean, if I'm oversimplifying, correct me, but, look, you have 5,000 multinationals you really target for payments, Capital Markets and Banking. Those companies have a lot of deposits, a lot of Services. That's the stickiness and that's where you said 80% of your clients in TTS have been with you for over 15 years. What if the deposits for those 5,000 multinationals, and I know I'm asking you to slice and dice in a little bit different way, but even just a general sense, because the reason I'm asking this is because I think there's April 14, 2023 a disconnect between showing percent of uninsured deposits as a measure of stickiness, and I don't think that's valid, and you've showed higher deposits even though you have a big percentage of uninsured deposits or maybe that doesn't matter as much as some front pages of newspapers are suggesting, so if you could address that.\"]\n",
            "Skipping invalid item in LLM output: [\"Yeah, thanks, Mike. Look, I'd tell you to turn to page 26 in the earnings presentation. We've broken down the deposits for each of the businesses that we have, and at the bottom, you see the TTS deposits, and this is where the 5,000 or so large multinational client deposits reside, and you can see the stability, as well as the steady growth in those deposits over time. And to your point, these are largely operational deposits that these clients have with us, and we shouldn't mistake rate sensitivity or betas with stickiness, right, and it's because these deposits tend to be quite sticky with us, as you can see here. Now, they're price-sensitive in the sense that as rates go up, we often have to reprice those. But remember, the relationships we have with these clients are broader than just deposit relationships, and that's what gives us the opportunity to adjust pricing accordingly with our deposits both in the US and outside of the US. And so the other page, in your own time you can look at it is the page prior to that which again speaks to the diversification of the portfolio but it also speaks to the length of time that many of these clients have been with us and have grown with us, and so nearly 80% of our deposits are from clients that have a greater than 15 year relationship with us, and that says a lot. And so anyway, those are the two points I'd make. Hopefully that addresses your question around the stickiness. Yeah, I often say it takes a root canal to extract us from the operations of our clients just because of exactly what we're talking about here, and that's also we see it even with the mid-market clients that are a growing portion here as well because we're helping them expand internationally, and that stickiness comes through and the LCR of 120% is a very high-quality LCR ratio.\", 1.0]\n",
            "Processed block: 21 of 86, extracted 2 questions and answers.\n",
            "Could not parse LLM output string: [   [\"So, I'm very curious on the whole revenue to RWA topic, especially with some of the changes coming in. So maybe you could give a little more color on -- let's take, for instance, the further reduction in subscription credit facilities. I think I read somewhere that was like an $80 billion book down to $20 billion. You can correct that if that's wrong. But just usually, those things are big important clients that have relationship lending, things attached to them. So, I'm curious on how you balance the capital benefit, the clear capital benefit, versus client impact and how you think about that? Are there other blocks of business that are in motion right now?\" ,   [\"Thanks Glenn and good morning, and thanks for the question. Look, a couple of points on that. One is we've been very focused on the revenue to RWA metric in our Markets business in the ICG more broadly as well. And we've made considerable progress on that. And that's important because how we use the balance sheet and ensuring that we're optimizing the use of the balance sheet contributes to how we improve returns over time. You're right to point out the subscription facility, credit facility, lending that we do. We brought that down pretty significantly. The numbers you highlight are a lot higher than the portfolio. But what's important here is that as we look at that, we look at a couple of things. So, one, the nature of relationship and whether clients are taking advantage of the breadth of what we have to offer. Two, the profitability and returns associated with the product to the extent that it is in a broader relationship, and where those returns are low, subpar, and the prospect for doing more has proven to be fruitless, we take it down. And that's what we've done with a large part of that book, just as we juxtapose it against other opportunities to use balance sheet where clients are taking advantage of the broader franchise and therefore, are generating higher returns. And we're going to continue to do that. We've done that to drive the revenue to RWA metric. We've done it selectively on pieces of the portfolio like SCF. We've also looked at our broader corporate lending portfolio and where those promises for higher relationship returns aren't manifesting themselves, we've not renewed those loans. And as we think about pending regulatory changes, proactively making these efforts becomes critically important. When I look back on the activity that we've done over the past couple of years, we've reduced RWA by approximately $120 billion over the last 2 years, and about 75% of that is predominantly driven by balance sheet optimization and looking at client activity that has low margin business. And so, this is important for us to do and to keep doing.\" ,   1.0 ] - Error: '[' was never closed (<unknown>, line 1)\n",
            "Processed block: 23 of 86, extracted 1 questions and answers.\n",
            "Processed block: 24 of 86, extracted 1 questions and answers.\n",
            "Processed block: 25 of 86, extracted 1 questions and answers.\n",
            "Processed block: 26 of 86, extracted 1 questions and answers.\n",
            "Processed block: 27 of 86, extracted 1 questions and answers.\n",
            "Processed block: 28 of 86, extracted 2 questions and answers.\n",
            "Processed block: 29 of 86, extracted 1 questions and answers.\n",
            "Processed block: 30 of 86, extracted 1 questions and answers.\n",
            "Processed block: 31 of 86, extracted 1 questions and answers.\n",
            "Processed block: 32 of 86, extracted 2 questions and answers.\n",
            "Processed block: 33 of 86, extracted 1 questions and answers.\n",
            "Processed block: 34 of 86, extracted 1 questions and answers.\n",
            "Processed block: 35 of 86, extracted 1 questions and answers.\n",
            "Processed block: 36 of 86, extracted 1 questions and answers.\n",
            "Processed block: 37 of 86, extracted 1 questions and answers.\n",
            "Processed block: 38 of 86, extracted 1 questions and answers.\n",
            "Processed block: 39 of 86, extracted 1 questions and answers.\n",
            "Processed block: 40 of 86, extracted 1 questions and answers.\n",
            "Processed block: 41 of 86, extracted 1 questions and answers.\n",
            "Processed block: 42 of 86, extracted 1 questions and answers.\n",
            "Processed block: 43 of 86, extracted 1 questions and answers.\n",
            "Processed block: 44 of 86, extracted 2 questions and answers.\n",
            "Processed block: 45 of 86, extracted 1 questions and answers.\n",
            "Processed block: 46 of 86, extracted 1 questions and answers.\n",
            "Processed block: 47 of 86, extracted 1 questions and answers.\n",
            "Processed block: 48 of 86, extracted 1 questions and answers.\n",
            "Processed block: 49 of 86, extracted 1 questions and answers.\n",
            "Processed block: 50 of 86, extracted 1 questions and answers.\n",
            "Processed block: 51 of 86, extracted 1 questions and answers.\n",
            "Processed block: 52 of 86, extracted 1 questions and answers.\n",
            "Processed block: 53 of 86, extracted 2 questions and answers.\n",
            "Processed block: 54 of 86, extracted 1 questions and answers.\n",
            "Processed block: 55 of 86, extracted 1 questions and answers.\n",
            "Processed block: 56 of 86, extracted 2 questions and answers.\n",
            "Processed block: 57 of 86, extracted 1 questions and answers.\n",
            "Processed block: 58 of 86, extracted 2 questions and answers.\n",
            "Processed block: 59 of 86, extracted 2 questions and answers.\n",
            "Processed block: 60 of 86, extracted 1 questions and answers.\n",
            "Processed block: 61 of 86, extracted 1 questions and answers.\n",
            "Processed block: 62 of 86, extracted 3 questions and answers.\n",
            "Processed block: 63 of 86, extracted 1 questions and answers.\n",
            "Processed block: 64 of 86, extracted 2 questions and answers.\n",
            "Processed block: 65 of 86, extracted 1 questions and answers.\n",
            "Processed block: 66 of 86, extracted 1 questions and answers.\n",
            "Could not parse LLM output string: [   [\"Hey, good afternoon. Mark, maybe just to follow up on the expense, slide 22, where you talk about $2 billion to $2.5 billion of expense saves. I guess I'm struggling with the numbers there. I think if you look at exit and wind- down markets, you're probably close to $2 billion in numbers there. And maybe the stranded costs, you can't get all of that out. You're doing about - severance is $700 million to $1 billion in 2024. So doesn't seem like there's a ton of actual cost saves in that number. And just maybe I'm wrong, if you could just kind of walk me through the numbers embedded in there and if there's, you've kind of eluded to more to come beyond the intermediate term.\",    \"Yeah, I think the thing I'd point out to you is a couple things. One, obviously, we're forecasting revenue growth over this period of time. And so, there's going to be volume-related expenses associated with that. The second thing I'd point out, as I just mentioned to the prior question, is that we're continuing to invest in risk and controls and in the transformation over this period of time. And so, what you see is there's an increase in expenses associated with at least those two things. And that's offset by the savings that we're starting to generate, particularly from the org simplification that Jane has talked about, as well as from the stranded cost reduction that will continue to play out, as well as from some of the rightsizing of businesses that we've referenced in some of the prepared remarks. And so, important to think about, there are headwinds and tailwinds that kind of net down to this $2 billion to $2.5 billion. And then the final point that I'd make is if I look at this medium-term number of $51 billion to $53 billion that still has Mexico in it and one of the other pages we'd point to, expenses around Mexico. But because of where we are, we'll be in the IPO process, that's still going to be part of this expense base, and so you can't lose sight of that.\",   0.7 ] - Error: '[' was never closed (<unknown>, line 1)\n",
            "Processed block: 68 of 86, extracted 1 questions and answers.\n",
            "Processed block: 69 of 86, extracted 1 questions and answers.\n",
            "Processed block: 70 of 86, extracted 1 questions and answers.\n",
            "Processed block: 71 of 86, extracted 1 questions and answers.\n",
            "Processed block: 72 of 86, extracted 1 questions and answers.\n",
            "Processed block: 73 of 86, extracted 1 questions and answers.\n",
            "Processed block: 74 of 86, extracted 0 questions and answers.\n",
            "No questions or answers found for following texts:\n",
            "Thank you, Jane. I think that it was very helpful that you said on this public forum where you're trying to build credibility, because as I think about what long-only investors have been dying to see from Citi in terms of the previous leadership was that sort of awareness. And I think just having that awareness recognition will be very important to investors, so thank you.\n",
            "Thank you.\n",
            "Processed block: 75 of 86, extracted 1 questions and answers.\n",
            "Processed block: 76 of 86, extracted 1 questions and answers.\n",
            "Processed block: 77 of 86, extracted 3 questions and answers.\n",
            "Processed block: 78 of 86, extracted 1 questions and answers.\n",
            "Processed block: 79 of 86, extracted 1 questions and answers.\n",
            "Processed block: 80 of 86, extracted 1 questions and answers.\n",
            "Processed block: 81 of 86, extracted 1 questions and answers.\n",
            "Processed block: 82 of 86, extracted 1 questions and answers.\n",
            "Processed block: 83 of 86, extracted 1 questions and answers.\n",
            "Processed block: 84 of 86, extracted 2 questions and answers.\n",
            "Processed block: 85 of 86, extracted 1 questions and answers.\n",
            "Processed block: 86 of 86, extracted 1 questions and answers.\n"
          ]
        }
      ],
      "source": [
        "# Extract all questions and answers\n",
        "result_list = []\n",
        "\n",
        "# For all extracted pairs\n",
        "for i, pair in enumerate(qa_pairs.iterrows()): # Iterate over DataFrame rows\n",
        "  # pair is a tuple of (index, Series)\n",
        "  question_text = pair[1]['question'] # Access 'question' column from the Series\n",
        "  answer_text = pair[1]['answer']   # Access 'answer' column from the Series\n",
        "\n",
        "  LLM_output_str = extract_questions_answers(question_text, answer_text)\n",
        "\n",
        "  # Delete newlines and spaces\n",
        "  LLM_output_str = \" \".join(LLM_output_str.splitlines()).strip()\n",
        "\n",
        "  try:\n",
        "    # Safely evaluate the string to a Python list\n",
        "    LLM_output_list = ast.literal_eval(LLM_output_str)\n",
        "\n",
        "    # Check if the evaluated output is a list and process it\n",
        "    if isinstance(LLM_output_list, list):\n",
        "      for item in LLM_output_list:\n",
        "        # Check if each item is a list with at least three elements\n",
        "        if isinstance(item, list) and len(item) >= 3:\n",
        "            result_list.append({\"bank\": pair[1]['bank'],# Access other columns from the Series\n",
        "                                \"year\": pair[1]['year'],\n",
        "                                \"quarter\": pair[1]['quarter'],\n",
        "                                \"tag\": pair[1]['tag'],\n",
        "                                \"question_speaker\": pair[1]['question_speaker'],\n",
        "                                \"analyst_firm\": pair[1]['analyst_firm'],\n",
        "                                \"extracted_question\": item[0],\n",
        "                                \"original_question_text\": question_text,\n",
        "                                \"answer_speaker\": pair[1]['answer_speaker'],\n",
        "                                \"extracted_answer\": item[1],\n",
        "                                \"original_answer_text\": answer_text,\n",
        "                                \"answer_score\": item[2]})\n",
        "\n",
        "        else:\n",
        "          print(f\"Skipping invalid item in LLM output: {item}\")\n",
        "      print(f\"Processed block: {i+1} of {len(qa_pairs)}, extracted {len(LLM_output_list)} questions and answers.\")\n",
        "\n",
        "      if len(LLM_output_list) == 0:\n",
        "        print(f\"No questions or answers found for following texts:\")\n",
        "        print(question_text)\n",
        "        print(answer_text)\n",
        "\n",
        "    else:\n",
        "      print(f\"LLM output is not a list: {LLM_output_str}\")\n",
        "\n",
        "  except (ValueError, SyntaxError) as e:\n",
        "    print(f\"Could not parse LLM output string: {LLM_output_str} - Error: {e}\")\n",
        "\n",
        "# Create DataFrame from the list of results\n",
        "result_df = pd.DataFrame(result_list)\n",
        "\n",
        "# Save as csv\n",
        "result_df.to_csv(\"qna_data.csv\", index=False, sep=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x-gSX4RsrgHS",
        "outputId": "3d77bc0f-c35c-4caa-e7fb-c3ef9bddc192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed question 1\n",
            "Processed question 2\n",
            "Processed question 3\n",
            "Processed question 4\n",
            "Processed question 5\n",
            "Processed question 6\n",
            "Processed question 7\n",
            "Processed question 8\n",
            "Processed question 9\n",
            "Processed question 10\n",
            "Processed question 11\n",
            "Processed question 12\n",
            "Processed question 13\n",
            "Processed question 14\n",
            "Processed question 15\n",
            "Processed question 16\n",
            "Processed question 17\n",
            "Processed question 18\n",
            "Processed question 19\n",
            "Processed question 20\n",
            "Processed question 21\n",
            "Processed question 22\n",
            "Processed question 23\n",
            "Processed question 24\n",
            "Processed question 25\n",
            "Processed question 26\n",
            "Processed question 27\n",
            "Processed question 28\n",
            "Processed question 29\n",
            "Processed question 30\n",
            "Processed question 31\n",
            "Processed question 32\n",
            "Processed question 33\n",
            "Processed question 34\n",
            "Processed question 35\n",
            "Processed question 36\n",
            "Processed question 37\n",
            "Processed question 38\n",
            "Processed question 39\n",
            "Processed question 40\n",
            "Processed question 41\n",
            "Processed question 42\n",
            "Processed question 43\n",
            "Processed question 44\n",
            "Processed question 45\n",
            "Processed question 46\n",
            "Processed question 47\n",
            "Processed question 48\n",
            "Processed question 49\n",
            "Processed question 50\n",
            "Processed question 51\n",
            "Processed question 52\n",
            "Processed question 53\n",
            "Processed question 54\n",
            "Processed question 55\n",
            "Processed question 56\n",
            "Processed question 57\n",
            "Processed question 58\n",
            "Processed question 59\n",
            "Processed question 60\n",
            "Processed question 61\n",
            "Processed question 62\n",
            "Processed question 63\n",
            "Processed question 64\n",
            "Processed question 65\n",
            "Processed question 66\n",
            "Processed question 67\n",
            "Processed question 68\n",
            "Processed question 69\n",
            "Processed question 70\n",
            "Processed question 71\n",
            "Processed question 72\n",
            "Processed question 73\n",
            "Processed question 74\n",
            "Processed question 75\n",
            "Processed question 76\n",
            "Processed question 77\n",
            "Processed question 78\n",
            "Processed question 79\n",
            "Processed question 80\n",
            "Processed question 81\n",
            "Processed question 82\n",
            "Processed question 83\n",
            "Processed question 84\n",
            "Processed question 85\n",
            "Processed question 86\n",
            "Processed question 87\n",
            "Processed question 88\n",
            "Processed question 89\n",
            "Processed question 90\n",
            "Processed question 91\n",
            "Processed question 92\n",
            "Processed question 93\n",
            "Processed question 94\n",
            "Processed question 95\n",
            "Processed question 96\n",
            "Processed question 97\n",
            "Processed question 98\n",
            "Processed question 99\n"
          ]
        }
      ],
      "source": [
        "# Check the properties of every question in the data and store\n",
        "for idx, row in result_df.iterrows():\n",
        "  question_properties = check_question_properties(row[\"extracted_question\"])\n",
        "\n",
        "  try:\n",
        "    question_properties_list = ast.literal_eval(question_properties)\n",
        "\n",
        "    if isinstance(question_properties_list, list) and len(question_properties_list) == 2:\n",
        "        result_df.loc[idx, \"orientation\"] = question_properties_list[0]\n",
        "        result_df.loc[idx, \"theme\"] = question_properties_list[1]\n",
        "        print(f\"Processed question {idx+1}\")\n",
        "    else:\n",
        "        print(f\"Skipping invalid item in LLM output: {question_properties_list}\")\n",
        "\n",
        "  except (ValueError, SyntaxError) as e:\n",
        "    print(f\"Could not parse LLM output string: {question_properties} - Error: {e}\")\n",
        "\n",
        "# Save to csv\n",
        "result_df.to_csv(\"qna_data.csv\", index=False, sep=\";\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
